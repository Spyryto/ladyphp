<?

class NewLady

  # ---------------------------------------------
  # constants
  # ---------------------------------------------
  const ENDED_LINE = '; { ( [ . + - , / * % = <?'   # ended line
  const REGEX_CLASS = ';^([A-Z].*|self|parent)$;'   # class name
  const REGEX_VARIABLE = ';^[_a-z].*;'              # variable name
  const REGEX_NOVARIABLE = ';^(false|true|self|parent|null)$;' # not variables
  const OUTPUT_HEAD = '# DO NOT EDIT THIS FILE. It was generated by LadyPHP.'

  const PRESERVE = 1  # preserve code formating and comments
  const STRIP    = 2  # strip comments, keep line numbers
  const COMPRESS = 4  # compress output code
  const NOCACHE  = 8  # always overwrite cache file

  # ---------------------------------------------
  # parse
  # convert LadyPHP from string to PHP code
  # ---------------------------------------------
  static fn parse(source)
    source = rtrim(str_replace("\r", '', source))
    tokens = self.tokenize(source)

    # process tokens
    foreach (tokens as n: token)
      extract(token, EXTR_OVERWRITE | EXTR_REFS)

      # convert 'fn' to 'function'
      if (str == 'fn')
        str = 'function'

      # add $ to variables
      if (type == T_STRING
          && tokens[n + 1]['str'] != '('
          && tokens[n - 1]['str'] != '->'
          && (tokens[n - 1]['str'] != '.'
             || preg_match(self.REGEX_CLASS, tokens[n - 2]['str']))
          && preg_match(self.REGEX_VARIABLE, str)
          && !preg_match(self.REGEX_NOVARIABLE, str))
        str = '$' . str

      # add 'new' before 'Foo()', support for namespaces
      i = 0
      while (((tokens[n + i]['type'] == T_STRING
          && preg_match(self.REGEX_CLASS, tokens[n + i]['str']))
          || tokens[n + i]['type'] == T_NS_SEPARATOR)
          && hasBlank
          && (!tokens[n + i]['hasBlank'] || i == 0)
          && tokens[n - 1]['type'] != T_NEW)
        if (tokens[n + i]['type'] == T_STRING
            && tokens[n + i + 1]['str'] == '(')
          str = 'new ' . str
          break
        i++

      # convert . to -> or ::
      if (str == '.'
          && (!hasBlank || !tokens[n + 1]['hasBlank']))
        if (preg_match(self.REGEX_CLASS, tokens[n - 1]['str']))
          str = '::'
        else
          str = '->'

      # convert : to =>
      if (str == ':' && !hasBlank)
        str = ' =>'

      # add semicolon
      if (isLast && !self.oneOf(str, self.ENDED_LINE))
        str .= ';'

      # convert php open tag
      if (type == T_OPEN_TAG)
        str = '<?php '
        if (y == 0)
          str .= self.OUTPUT_HEAD

      # save token
      tokens[n] = token

    # glue code
    code = null
    foreach (tokens as n: token)
      code .= token['blank'] . token['str']
    return code

  # ---------------------------------------------
  # oneOf
  # return true if needle is one of words in values
  # ---------------------------------------------
  static fn oneOf(needle, values)
    return in_array(needle, explode(' ', values))

  # ---------------------------------------------
  # tokenize
  # ---------------------------------------------
  static fn tokenize(source)
    newTokens = []
    blank = null

    # get tokens
    tokens = token_get_all(source)

    # convert to associative arrays
    foreach (tokens as n: token)
      if (is_array(token))
        tokens[n] = ['str': token[1], 'type': token[0], 'name': token_name(token[0])]
      else
        tokens[n] = ['str': token, 'type': null, 'name': null]

    # save whitespaces and comments into tokens
    foreach (tokens as n: token)
      if (in_array(token['name'], [T_COMMENT, T_DOC_COMMENT, T_WHITESPACE]))
        blank .= token['str']
      else
        token['blank'] = blank
        token['hasBlank'] = (blank != null)
        blank = null
        newTokens[] = token
    tokens = newTokens

    # get positions
    foreach (tokens as n: token)
      # first token
      if (n == 0)
        tokens[n]['x'] = tokens[n]['y'] = 0
        tokens[n]['isFirst'] = true
      # another token
      else
        # get x, y
        tokens[n]['x'] = mb_strlen(array_slice(explode("\n", token['blank']), -1)[0])
        tokens[n]['y'] = tokens[n - 1]['y'] + count(explode("\n", token['blank'] . token['str'])) - 1
        # set isFirst and isLast flags
        tokens[n]['isFirst'] = (tokens[n - 1]['y'] != tokens[n]['y'])
        tokens[n - 1]['isLast'] = (tokens[n - 1]['y'] != tokens[n]['y'])
        # add horizontal size of previous tokens to non-first token
        if (!tokens[n]['isFirst'])
          tokens[n]['x'] += tokens[n - 1]['x'] + mb_strlen(tokens[n - 1]['str'])
      # set isLast flag in last token
      if (n == count(tokens) - 1)
        tokens[n]['isLast'] = true

    # output
    return tokens


  # ---------------------------------------------
  # cacheFile
  # check cacheFile, parse if it's old
  # ---------------------------------------------
  static fn cacheFile(file, cacheFile, flags = 0)
    if (!is_dir(dirname(cacheFile)))
      mkdir(dirname(cacheFile), 0755, true)
    if (!is_file(cacheFile) || filemtime(cacheFile) <= filemtime(file) || flags & self.NOCACHE)
      file_put_contents(cacheFile, self.parseFile(file, null, flags))
    return cacheFile

  # ---------------------------------------------
  # parseFile
  # load file and parse it
  # ---------------------------------------------
  static fn parseFile(file, cacheFile = null, flags = 0)
    if (cacheFile == null)
      return self.parse(file_get_contents(file), flags)
    else
      return file_get_contents(self.cacheFile(file, cacheFile, flags))

  # ---------------------------------------------
  # includeFile
  # parse file and execute it
  # ---------------------------------------------
  static fn includeFile(file, cacheFile = null, flags = 0)
    if (cacheFile == null)
      return eval('?>' . self.parseFile(file, null, flags))
    else
      return require_once(self.cacheFile(file, cacheFile, flags))

  # ---------------------------------------------
  # testFile
  # parse file and show input and output as html
  # ---------------------------------------------
  static fn testFile(file, flags = 0)
    input = file_get_contents(file)
    output = self.parseFile(file, null, flags)
    pre = '<pre style="max-height:40em;max-width:30em;float:left;overflow:auto;font-size:12px;border:1px solid gray;padding:.2em;background-color:#fafafa">'
    html = '<div><h3 style="margin:0">' . file . '</h3>'
    foreach ([input, output] as text)
      html .= pre
      foreach (explode("\n", text) as n: line)
        html .= sprintf('%3d: %s', n, htmlspecialchars(line)) . "\n"
      html .= '</pre>'
    html .= '<hr style="height=0;border:none;clear:both"></div>'
    return html

  # ---------------------------------------------
  # compress
  # strip comments and compress php source
  # ---------------------------------------------
  static fn compress(php)
    if (!defined('T_DOC_COMMENT'))
      define('T_DOC_COMMENT', -1)
    if (!defined('T_ML_COMMENT'))
      define('T_ML_COMMENT', -1)

    space = output = ''
    set = '!"#$&\'()*+,-./:;<=>?@[\]^`{|}'
    set = array_flip(preg_split('//',set))

    foreach (token_get_all(php) as token)
      if (!is_array(token))
        token = [0, token]
      if (in_array(token[0], [T_COMMENT, T_ML_COMMENT, T_DOC_COMMENT, T_WHITESPACE]))
        space = "\n"
      else
        if (isset(set[substr(output, -1)]) || isset(set[token[1]{0}]))
          space = ''
        output .= space . token[1]
        space = ''
    return output

