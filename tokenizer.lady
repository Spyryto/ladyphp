<?

class LadyTokenizer

  # ---------------------------------------------
  # tokenize
  # ---------------------------------------------
  static fn tokenize(source)
    newTokens = []
    blank = null

    # get tokens
    tokens = token_get_all(source)

    # convert string tokens to arrays
    foreach (tokens as n: token)
      id = name = str = line = null
      if (is_array(token))
        id = token[0]
        name = token_name(token[0])
        str = token[1]
      else
        str = token
      tokens[n] = compact('id', 'name', 'str')

    # remove whitespaces and comments
    foreach (tokens as n: token)
      if (in_array(token['id'], [T_WHITESPACE, T_COMMENT]))
        blank .= token['str']
      else
        token['blank'] = blank
        token['afterBlank'] = (blank !== null)
        blank = null
        newTokens[] = token
    tokens = newTokens

    # get horizontal position
    foreach (tokens as n: token)
      if (n == 0)
        tokens[n]['y'] = 0
        tokens[n]['x'] = 0
      else
        tokens[n]['y'] = tokens[n - 1]['y'] + count(explode("\n", token['blank'] . token['str'])) - 1
        tokens[n]['x'] = mb_strlen(array_slice(explode("\n", token['blank']), -1)[0])
        tokens[n]['firstOnLine'] = (tokens[n - 1]['y'] != tokens[n]['y'])
        if (!tokens[n]['firstOnLine'])
          tokens[n]['x'] += tokens[n - 1]['x'] + mb_strlen(tokens[n - 1]['str'])

    return tokens

